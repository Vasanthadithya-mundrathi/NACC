"""
NACC Professional UI v2 - Modern Dark-Themed Enterprise Interface
Complete rewrite with clean 50/50 split layout
"""

import gradio as gr
import json
import requests
import os
from typing import List, Dict, Any, Optional, Tuple
from datetime import datetime
import hashlib
import logging

# Import the existing components
from .ai_intent_parser import AIIntentParser
from .conversational_ui import NACCConversationUI, SessionState, get_nacc_workspace
from pathlib import Path

# Orchestrator URL
ORCHESTRATOR_URL = os.getenv("NACC_ORCHESTRATOR_URL", "http://127.0.0.1:8888")

# Setup logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class ModernNACCUI(NACCConversationUI):
    """Modern redesigned UI with clean dark theme"""
    
    def __init__(self):
        super().__init__()
        
    def parse_and_enhance_response(self, result: Dict, message: str) -> str:
        """Parse orchestrator response and enhance with rich formatting"""
        bot_response = result.get("response", "")
        execution = result.get("execution", {})
        
        # Check execution results for additional context
        if execution and "results" in execution:
            exec_results = execution.get("results", [])
            if exec_results:
                first_result = exec_results[0]
                stdout = first_result.get("stdout", "").strip()
                stderr = first_result.get("stderr", "").strip()
                exit_code = first_result.get("exit_code", 0)
                
                # Enhance response based on command type
                if "install" in message.lower() and "package" in message.lower():
                    if exit_code == 0:
                        bot_response += f"\n\nâœ… **Installation completed successfully!**"
                    else:
                        bot_response += f"\n\nâš ï¸ **Installation may have issues** (exit code: {exit_code})"
                
                if "read file" in message.lower() or "cat" in message.lower():
                    if stdout:
                        bot_response = f"ğŸ“„ **File Content:**\n\n```\n{stdout}\n```"
                
                if "execute" in message.lower():
                    # Enhanced command output display
                    if stdout or stderr:
                        bot_response += f"\n\n**Output:**\n```\n{stdout if stdout else stderr}\n```"
                    if exit_code == 0:
                        bot_response += f"\n\nâœ… Exit code: {exit_code}"
                    else:
                        bot_response += f"\n\nâš ï¸ Exit code: {exit_code}"
        
        return bot_response
    
    def handle_chat(self, message: str, history: List, session_id: str) -> Tuple[List, str, str, str, str]:
        """Handle chat messages with AI processing and enhanced response parsing"""
        if not message.strip():
            return history, "", self.get_dashboard_view(), self.list_files_view(), session_id
        
        # Get session
        session = self.get_or_create_session(session_id)
        
        # Process message
        try:
            response = requests.post(
                f"{ORCHESTRATOR_URL}/chat",
                json={
                    "query": message,
                    "session_id": session.session_id,
                    "current_node": session.current_node,
                    "current_path": session.current_path,
                    "timeout": 120  # Increased for AI backends (Modal/Blaxel take 50-60s)
                },
                timeout=180  # 3 minutes - enough for any backend
            )
            
            if response.status_code == 200:
                result = response.json()
                # Enhanced response parsing
                bot_response = self.parse_and_enhance_response(result, message)
                
                # Update session context
                if "context" in result:
                    session.current_node = result["context"].get("current_node", session.current_node)
                    session.current_path = result["context"].get("current_path", session.current_path)
                
            else:
                bot_response = f"âš ï¸ Error: {response.status_code} - {response.text}"
                
        except Exception as e:
            bot_response = f"âŒ Connection error: {str(e)}"
        
        # Add to history
        history = history + [[message, bot_response]]
        
        # Update views dynamically based on current session state
        dashboard = self.get_dashboard_view(session)
        files = self.list_files_view(session.current_path, session.current_node)
        
        return history, "", dashboard, files, session_id
    
    def get_dashboard_view(self, session: Optional[SessionState] = None) -> str:
        """Get real-time network dashboard with current node highlighted"""
        # Use default values if no session
        current_node = session.current_node if session else "macbook-local"
        current_path = session.current_path if session else get_nacc_workspace()
        try:
            response = requests.get(f"{ORCHESTRATOR_URL}/nodes", timeout=5)
            if response.status_code == 200:
                nodes = response.json()
                
                active = len([n for n in nodes if n.get('healthy', False)])
                total = len(nodes)
                
                dashboard = f"""ğŸŒ **Network Dashboard**
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“Š **System Overview**
   â€¢ Total Nodes: {total}
   â€¢ Active: {active} âœ…
   â€¢ Offline: {total - active} âš ï¸
   â€¢ Health Score: {(active/total*100) if total > 0 else 0:.0f}%
   
ğŸ“ **Current Node**: {current_node}
ğŸ“ **Current Path**: {current_path}

ğŸ–¥ï¸ **Connected Nodes**
"""
                for node in nodes:
                    status = "âœ…" if node.get('healthy') else "âš ï¸"
                    is_current = " â—€ï¸ ACTIVE" if node.get('node_id') == current_node else ""
                    node_id = node.get('node_id', 'Unknown')
                    tags = ', '.join(node.get('tags', []))
                    dashboard += f"   {status} {node_id} ({tags}){is_current}\n"
                
                dashboard += "\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
                dashboard += f"ğŸ• Last Updated: {datetime.now().strftime('%H:%M:%S')}\n"
                dashboard += "Status: Operational ğŸŸ¢\n"
                
                return dashboard
            else:
                return "âš ï¸ Unable to fetch dashboard data"
        except Exception as e:
            return f"âŒ Dashboard Error: {str(e)}"
    
    def list_files_view(self, path: str = None, node: str = "macbook-local") -> str:
        """List files in current directory on specified node"""
        if path is None:
            path = get_nacc_workspace()
        
        try:
            # Determine preferred tags based on node
            preferred_tags = ["mac", "local"] if node == "macbook-local" else ["kali", "vm"]
            node_label = "MacBook Pro" if node == "macbook-local" else "Kali VM"
            
            # Use orchestrator's execute command endpoint
            response = requests.post(
                f"{ORCHESTRATOR_URL}/commands/execute",
                json={
                    "description": f"List files in {path} on {node}",
                    "command": ["ls", "-lah", path],
                    "preferred_tags": preferred_tags,
                    "timeout": 30
                },
                timeout=60  # Increased from 15s to 60s
            )
            
            if response.status_code == 200:
                result = response.json()
                # Get output from first result
                results = result.get("results", [])
                if results and len(results) > 0:
                    output = results[0].get("stdout", "")
                    
                    files_view = f"""ğŸ“‚ **File Browser: {path}** (on {node_label})
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ–¥ï¸ Node: {node}
ğŸ“ Path: {path}

{output}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
"""
                    return files_view
                else:
                    return f"ğŸ“ **{path}**\n\nNo results from node"
            else:
                return f"ğŸ“ **{path}**\n\nâš ï¸ Error: {response.status_code}"
        except Exception as e:
            return f"ğŸ“ **{path}**\n\nâŒ Error: {str(e)}"
    
    def get_available_backends(self) -> Tuple[List[str], str]:
        """Fetch available backends from orchestrator"""
        try:
            response = requests.get(f"{ORCHESTRATOR_URL}/backends/available", timeout=5)
            if response.status_code == 200:
                data = response.json()
                backends = data.get("backends", [])
                choices = []
                info = "**ğŸ¤– Available AI Backends:**\n\n"
                
                for backend in backends:
                    name = backend["name"]
                    display = backend["display_name"]
                    model = backend.get("model", "N/A")
                    is_free = backend["is_free"]
                    requires_key = backend["requires_api_key"]
                    
                    # Format: "modal - Modal A100 FREE (IBM Granite MoE)"
                    label = f"{name} - {display}"
                    if is_free:
                        label += " ğŸ†“"
                    if requires_key:
                        label += " ğŸ”‘"
                    
                    choices.append((label, name))
                    
                    # Add to info
                    status = "ğŸ†“ FREE" if is_free else "ğŸ’³ Paid"
                    key_status = "ğŸ”‘ API Key Required" if requires_key else "âœ¨ No Key"
                    info += f"**{display}** ({status}, {key_status})\n"
                    info += f"   â€¢ Model: {model}\n"
                    info += f"   â€¢ Description: {backend['description']}\n\n"
                
                return choices, info
            else:
                return [("modal", "modal")], "âš ï¸ Failed to load backends"
        except Exception as e:
            return [("modal", "modal")], f"âŒ Error: {str(e)}"
    
    def get_backend_status(self) -> str:
        """Get current backend status"""
        try:
            response = requests.get(f"{ORCHESTRATOR_URL}/backends/current", timeout=5)
            if response.status_code == 200:
                data = response.json()
                display = data.get("display_name", "Unknown")
                name = data.get("backend", "unknown")
                model = data.get("model", "N/A")
                return f"**âœ… Active Backend:** {display} ({name})\n**ğŸ¤– Model:** {model}"
            else:
                return "âš ï¸ Unable to fetch backend status"
        except Exception as e:
            return f"âŒ Error: {str(e)}"
    
    def switch_backend(self, backend_name: str, api_key: str = "") -> Tuple[str, bool]:
        """Switch to a different AI backend"""
        try:
            payload = {"backend": backend_name}
            if api_key and api_key.strip():
                payload["api_key"] = api_key.strip()
            
            response = requests.post(
                f"{ORCHESTRATOR_URL}/backends/switch",
                json=payload,
                timeout=10
            )
            
            if response.status_code == 200:
                data = response.json()
                msg = f"âœ… **Success!**\n\n{data.get('message', 'Backend switched')}"
                return msg, True
            else:
                error = response.json().get("detail", response.text)
                msg = f"âŒ **Failed to switch backend**\n\n{error}"
                return msg, False
        except Exception as e:
            return f"âŒ **Error:** {str(e)}", False
    
    def on_backend_change(self, backend_value: str) -> Dict:
        """Handle backend dropdown change - show/hide API key field"""
        # Extract actual backend name from dropdown value (format: "modal - Modal A100 ğŸ†“")
        backend_name = backend_value.split(" - ")[0] if " - " in backend_value else backend_value
        
        # Check if this backend requires API key
        try:
            response = requests.get(f"{ORCHESTRATOR_URL}/backends/available", timeout=5)
            if response.status_code == 200:
                backends = response.json().get("backends", [])
                for b in backends:
                    if b["name"] == backend_name:
                        if b["requires_api_key"]:
                            return gr.update(visible=True)
                        else:
                            return gr.update(visible=False)
        except:
            pass
        
        return gr.update(visible=False)
    
    def execute_health_check(self) -> str:
        """Execute comprehensive health checks"""
        try:
            # Get orchestrator health
            health_response = requests.get(f"{ORCHESTRATOR_URL}/healthz", timeout=5)
            
            # Get nodes status
            nodes_response = requests.get(f"{ORCHESTRATOR_URL}/nodes", timeout=5)
            
            result = """âœ… **Health Check Results**
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ” **System Checks**
"""
            
            # Orchestrator status
            if health_response.status_code == 200:
                result += "   â€¢ Orchestrator: âœ… Healthy\n"
            else:
                result += "   â€¢ Orchestrator: âš ï¸ Degraded\n"
            
            # Nodes status
            if nodes_response.status_code == 200:
                nodes = nodes_response.json()
                result += f"   â€¢ Connected Nodes: {len(nodes)}\n\n"
                
                result += "ğŸ–¥ï¸ **Node Health**\n"
                for node in nodes:
                    node_id = node.get('node_id', 'Unknown')
                    healthy = node.get('healthy', False)
                    metrics = node.get('metrics', {})
                    
                    icon = "âœ…" if healthy else "âš ï¸"
                    result += f"   {icon} {node_id}: {'Healthy' if healthy else 'Offline'}\n"
                    
                    if healthy and metrics:
                        cpu = metrics.get('cpu_percent', 0)
                        mem = metrics.get('memory_percent', 0)
                        disk = metrics.get('disk_percent', 0)
                        result += f"      CPU: {cpu:.1f}% | Memory: {mem:.1f}% | Disk: {disk:.1f}%\n"
            else:
                result += "   â€¢ Nodes: âš ï¸ Unable to fetch\n"
            
            result += "\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
            result += "âœ… All systems operational\n"
            
            return result
            
        except Exception as e:
            return f"""âŒ **Health Check Failed**
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Error: {str(e)}

Please ensure orchestrator is running at:
{ORCHESTRATOR_URL}
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
"""


def create_professional_ui_v2():
    """Create the modern professional UI"""
    nacc = ModernNACCUI()
    
    # Custom CSS - COMPACT IDE THEME
    custom_css = """
    @import url('https://fonts.googleapis.com/css2?family=JetBrains+Mono:wght@400;600&family=Inter:wght@300;400;600&display=swap');

    :root {
        --body-background-fill: #0d1117 !important;
        --background-fill-primary: #161b22 !important;
        --background-fill-secondary: #0d1117 !important;
        --border-color-primary: #30363d !important;
        --color-accent: #58a6ff !important;
        --text-color: #c9d1d9 !important;
    }
    
    .gradio-container {
        font-family: 'Inter', sans-serif !important;
        background: #0d1117 !important;
        color: #c9d1d9 !important;
        padding: 0 !important;
        margin: 0 !important;
    }
    
    /* Remove huge gaps */
    .gap { gap: 0.5rem !important; }
    .compact { padding: 0 !important; margin: 0 !important; }
    
    /* Sidebar */
    #sidebar {
        background: #161b22 !important;
        border-right: 1px solid #30363d !important;
        padding: 1rem !important;
        height: 100vh !important;
    }
    
    /* Chat Area */
    #chat-area {
        background: #0d1117 !important;
        padding: 1rem !important;
    }
    
    /* File Tree Look */
    .file-tree textarea {
        font-family: 'JetBrains Mono', monospace !important;
        font-size: 0.85rem !important;
        background: transparent !important;
        border: none !important;
        line-height: 1.5 !important;
        color: #8b949e !important;
    }
    
    /* Chatbot */
    #main-chatbot {
        background: transparent !important;
        border: none !important;
        height: 70vh !important;
    }
    .message-wrap {
        background: #161b22 !important;
        border: 1px solid #30363d !important;
    }
    .user {
        background: #1f6feb22 !important; /* Blue tint */
        border-color: #1f6feb44 !important;
    }
    
    /* Inputs */
    input, textarea {
        background: #0d1117 !important;
        border: 1px solid #30363d !important;
        color: #c9d1d9 !important;
    }
    input:focus, textarea:focus {
        border-color: #58a6ff !important;
    }
    
    /* Compact Buttons */
    button {
        background: #21262d !important;
        border: 1px solid #30363d !important;
        color: #c9d1d9 !important;
        font-size: 0.85rem !important;
    }
    button:hover {
        background: #30363d !important;
        border-color: #8b949e !important;
    }
    button.primary {
        background: #238636 !important; /* GitHub Green */
        color: white !important;
        border: none !important;
    }
    
    /* Accordion */
    .label-wrap {
        background: transparent !important;
        border: none !important;
        font-size: 0.9rem !important;
    }
    
    /* Scrollbars */
    ::-webkit-scrollbar {
        width: 8px;
        height: 8px;
    }
    ::-webkit-scrollbar-track {
        background: #0d1117;
    }
    ::-webkit-scrollbar-thumb {
        background: #30363d;
        border-radius: 4px;
    }
    """
    
    # Build the Gradio Interface
    with gr.Blocks(
        theme=gr.themes.Soft(primary_hue="blue", secondary_hue="slate"),
        css=custom_css,
        title="NACC Enterprise AI - Professional Network Orchestration"
    ) as demo:
        
        # Session state
        session_id = gr.State()
        
        # Main Layout: VS Code Style (Left Sidebar | Main Chat)
        with gr.Row(elem_id="main-container", variant="panel", equal_height=True):
            
            # LEFT SIDEBAR (25%) - Files & Context
            with gr.Column(scale=1, elem_id="sidebar"):
                gr.Markdown("### ğŸ“‚ Explorer")
                
                # File Browser
                with gr.Group():
                    gr.Markdown(f"`{get_nacc_workspace()}`", elem_classes="path-display")
                    with gr.Row():
                        up_btn = gr.Button("â¬†ï¸", size="sm", min_width=10)
                        refresh_btn = gr.Button("ğŸ”„", size="sm", min_width=10)
                    
                    file_output = gr.Textbox(
                        label="",
                        value=nacc.list_files_view(),
                        lines=15,
                        interactive=False,
                        show_copy_button=True,
                        elem_classes="file-tree",
                        container=False
                    )
                
                gr.Markdown("### ğŸ“Š System")
                # Mini Dashboard
                dashboard_output = gr.Textbox(
                    label="",
                    value=nacc.get_dashboard_view(),
                    lines=10,
                    interactive=False,
                    elem_classes="mini-dashboard",
                    container=False
                )
                refresh_dash = gr.Button("Refresh Status", size="sm")

            # MAIN CHAT AREA (75%)
            with gr.Column(scale=3, elem_id="chat-area"):
                
                # Header & Settings
                with gr.Row(elem_id="chat-header"):
                    with gr.Column(scale=4):
                        gr.Markdown("# ğŸš€ NACC Agent")
                    with gr.Column(scale=1):
                         # Compact Settings
                        with gr.Accordion("âš™ï¸ Settings", open=False):
                            backend_dropdown = gr.Dropdown(
                                label="Backend",
                                choices=[],
                                value="blaxel-openai",
                                interactive=True,
                                container=False
                            )
                            api_key_input = gr.Textbox(
                                placeholder="API Key",
                                type="password",
                                visible=False,
                                container=False
                            )
                            switch_button = gr.Button("Apply", size="sm")
                            backend_status = gr.Markdown("Ready", elem_classes="status-text")

                # Chat Interface
                chatbot = gr.Chatbot(
                    value=[],
                    height=650,
                    show_label=False,
                    avatar_images=(None, "ğŸ¤–"),
                    bubble_full_width=False,
                    show_copy_button=True,
                    type="tuples",
                    elem_id="main-chatbot"
                )
                
                # Input Area
                with gr.Row(elem_classes="input-row"):
                    msg_input = gr.Textbox(
                        placeholder="Type a command... (e.g., 'create file', 'switch node')",
                        show_label=False,
                        scale=10,
                        container=False,
                        autofocus=True,
                        lines=1
                    )
                    send_btn = gr.Button("â¤", scale=1, variant="primary", min_width=50)

                # Footer / Disclaimer
                gr.Markdown(
                    """
                    <div style="display: flex; justify-content: space-between; font-size: 0.8em; color: #64748b; margin-top: 5px;">
                        <span>âš ï¸ Blaxel Sandbox: 30-70s processing</span>
                        <span>Context: macbook-local</span>
                    </div>
                    """
                )

        # Hidden components for logic
        backend_info = gr.Markdown("", visible=False)
        current_path = gr.State(value=get_nacc_workspace())
        cd_btn = gr.Button("Open", visible=False)
        refresh_backends_btn = gr.Button("Refresh", visible=False)
        
        # Removed unused tabs/components from previous layout to clean up
        # (ex1, ex2, etc. logic will need to be updated or removed if buttons are gone)
        # Keeping buttons hidden if needed for existing callbacks, or we remove callbacks.
        # Let's keep the callbacks but remove the buttons from UI to avoid errors if referenced.
        # Actually, better to define them as hidden if I don't want to rewrite all callbacks right now.
        ex1 = gr.Button(visible=False)
        ex2 = gr.Button(visible=False)
        ex3 = gr.Button(visible=False)
        ex4 = gr.Button(visible=False)
                    
                    # Tab 3: Help & Documentation
                    with gr.Tab("ğŸ“š Help & Examples"):
                        help_output = gr.Textbox(
                            label="NACC Complete Guide",
                            value=f"""ğŸ“š NACC - Network Agentic Connection Call
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ¯ WHAT IS NACC?

NACC is an AI-powered multi-node orchestration platform that lets you:
âœ… Manage multiple servers with natural language
âœ… Execute commands across your infrastructure
âœ… Switch between 8 different AI backends
âœ… Browse files and directories anywhere
âœ… Monitor system health in real-time

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“ YOUR NACC WORKSPACE

Location: {get_nacc_workspace()}

This is where NACC stores files you create. All AI operations happen here
unless you specify a different path.

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ› ï¸ AVAILABLE TOOLS & MCPs

ğŸ“ FILE OPERATIONS
   write_file    - Create/update files
   read_file     - Read file contents
   list_files    - Browse directories
   delete_file   - Remove files
   
   Examples:
   â€¢ "create a file called test.txt with hello world"
   â€¢ "read the contents of test.txt"

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ¤– BACKEND DETAILS

âœ… **RECOMMENDED:**
â€¢ Blaxel Sandbox (OpenAI) - FREE, Reliable, Fast

OTHER OPTIONS:
â€¢ Modal A100         - IBM Granite 3B (FREE)
â€¢ Docker Mistral     - Local 12B model (FREE)
â€¢ Blaxel Gemini      - 10 FREE requests
â€¢ Local Heuristic    - Rule-based fallback (FREE)

PAID (Requires Key):
â€¢ OpenAI GPT-4, Google Gemini, Cerebras Llama


ğŸ–¥ï¸ COMMAND EXECUTION
   execute_command - Run shell commands
   
   Examples:
   â€¢ "check disk space"
   â€¢ "show running processes"
   â€¢ "list network connections"

ğŸŒ NODE MANAGEMENT
   switch_node   - Change active server
   list_nodes    - Show all nodes
   node_status   - Check node health
   
   Examples:
   â€¢ "switch to kali-vm"
   â€¢ "show all available nodes"
   â€¢ "check status of macbook-local"

ğŸ“Š MONITORING
   system_metrics - CPU/RAM/Disk usage
   network_status - Node connectivity
   
   Examples:
   â€¢ "show system metrics"
   â€¢ "what's my CPU usage?"
   â€¢ "network dashboard"

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ’¡ EXAMPLE COMMANDS (Copy & Try These!)

Basic File Operations:
1. "write hello world to greeting.txt"
2. "read greeting.txt"
3. "list all files"
4. "create a Python script that prints hello"

Multi-Node Operations:
5. "switch to kali-vm"
6. "list files in /home/vasanth"
7. "switch back to macbook-local"
8. "show all connected nodes"

System Monitoring:
9. "show network dashboard"
10. "what's my current node and path?"
11. "check disk space"
12. "show system metrics"

Advanced Operations:
13. "create 5 test files named test1.txt through test5.txt"
14. "read all txt files and show their contents"
15. "execute ls -la command"
16. "sync files from kali-vm to macbook-local"

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“ HOW TO USE NACC

1. CHECK YOUR CONTEXT
   Look at top indicator showing:
   ğŸ–¥ï¸ Node: Your current server
   ğŸ“ Path: Your current directory  
   ğŸ› ï¸ Tool: What NACC is doing
   ğŸ”§ MCP: Which protocol is active

2. WRITE NATURAL COMMANDS
   Just type what you want:
   "create a file"
   "list my files"
   "switch to kali"
   
3. SWITCH BACKENDS
   Use dropdown at top to change AI provider
   â€¢ Free options work instantly
   â€¢ Paid options need API key
   â€¢ Docker Mistral is fastest free option (51s)

4. BROWSE FILES
   Click "File Browser" tab to see directory listing
   Navigate with buttons or type path

5. MONITOR SYSTEMS
   Click "Dashboard" tab for real-time metrics
   See CPU, RAM, disk, uptime for all nodes

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ—ï¸ ARCHITECTURE

Frontend (This UI)
  â†“ HTTP/REST
Orchestrator (Port 8888)
  â†“ MCP Protocol
Node Agents (Each server)
  â†“ Shell/OS
Your Systems

AI Backend (Port varies)
  â†’ Modal/Docker/Blaxel/etc
  â†’ Natural language â†’ JSON tools

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸš€ QUICK START

1. Try file operations:
   "write hello to test.txt"
   
2. Check your nodes:
   "show all nodes"
   
3. Browse directories:
   Click "File Browser" tab
   
4. Switch AI backends:
   Use dropdown at top
   
5. Monitor systems:
   Click "Dashboard" tab

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“ TROUBLESHOOTING

Q: "Command takes too long"
A: Some AI backends take 50-60s. Try Docker Mistral (fastest free)
   or use paid Cerebras (<5s)

Q: "File not found"
A: Check your workspace: {get_nacc_workspace()}
   Or specify full path: "read /home/user/file.txt"

Q: "Permission denied"
A: Some commands restricted by security. Check orchestrator logs.

Q: "Node offline"
A: Check Dashboard tab. Restart node agent if needed.

Q: "Wrong node"
A: Use "switch to [node-name]" to change active node

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ¯ PRO TIPS

â€¢ Use Docker Mistral for fastest free responses (51s)
â€¢ Specify full paths to avoid confusion
â€¢ Check context indicator before executing
â€¢ Use File Browser tab to navigate visually
â€¢ Switch backends for speed vs quality tradeoff
â€¢ All files created go to {get_nacc_workspace()}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Created: {datetime.now().strftime('%Y-%m-%d %H:%M')}
Version: 2.0 (Multi-Backend Support)
Status: âœ… Operational""",
                            lines=40,
                            interactive=False,
                            elem_classes="output-text"
                        )
                
                # Tab 4: Examples Gallery
                with gr.Tab("ğŸ¯ Try These Examples!"):
                    ex_col1, ex_col2 = gr.Row(), gr.Row()
                    
                    with ex_col1:
                        gr.Markdown("""### ï¿½ Copy & Paste These Commands!
                        
**Basic File Operations:**
```
write hello world to myfile.txt
```
```
read myfile.txt
```
```
list all files in my workspace
```
```
create a Python script hello.py that prints hello world
```

**Node Management:**
```
show all available nodes
```
```
switch to kali-vm
```
```
what's my current node and path?
```
```
switch back to macbook-local
```

**System Monitoring:**
```
show network dashboard
```
```
check disk space
```
```
what's my CPU usage?
```
```
show system metrics for all nodes
```
""")
                    
                    with ex_col2:
                        gr.Markdown("""### ğŸ“ What NACC Will Show You

For each command, NACC displays:

**1. Current Context (Top Indicator)**
- ğŸ–¥ï¸ **Node:** Which server you're on
- ğŸ“ **Path:** Current directory
- ğŸ› ï¸ **Tool:** What operation is running
- ğŸ”§ **MCP:** Protocol being used

**2. AI Reasoning**
- What tool it chose
- Why it chose that tool
- Parameters it's using

**3. Execution Results**
- Command output
- Success/failure status
- Any errors or warnings

**4. Updated State**
- New files created
- Directory changes
- Node switches

**Example Output:**
```
ğŸ–¥ï¸ Node: macbook-local
ğŸ“ Path: ~/nacc-workspace
ğŸ› ï¸ Tool: write_file
ğŸ”§ MCP: filesystem

âœ… Successfully created myfile.txt
ğŸ“„ Content: "hello world"
```
""")
                    
                    gr.Markdown(f"""
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

### ğŸ¯ Real Examples from This Session

**Your NACC Workspace:** `{get_nacc_workspace()}`

**Try These Right Now:**

1. **Create Your First File:**
   `write my name is [your name] to intro.txt`
   
2. **List Your Workspace:**
   `show all files in my workspace`
   
3. **Read What You Created:**
   `read intro.txt`
   
4. **Check Your System:**
   `show network dashboard`
   
5. **Switch Nodes:**
   `list all available nodes`

**Advanced Examples:**

6. **Create Multiple Files:**
   `create 3 files test1.txt, test2.txt, test3.txt with different content`
   
7. **Python Script:**
   `write a Python script calculator.py that adds two numbers`
   
8. **System Info:**
   `execute uname -a command to show system info`
   
9. **Navigate Directories:**
   `list files in /usr/local/bin`
   
10. **Multi-Node Operation:**
    `sync all txt files from macbook to kali-vm`

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

### âš¡ Performance Tips

- **Fastest Free AI:** Docker Mistral (51s) 
- **Best Quality Free:** Modal A100 (55s)
- **Fastest Paid:** Cerebras (<5s) - needs API key
- **Best Quality Paid:** OpenAI GPT-4 (<10s) - needs API key

**Switch backends at the top of this page!**

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
""")

        
        # Status Bar at bottom
        with gr.Row():
            status = gr.Markdown(
                """
                <div class='status-bar'>
                âœ… <strong>Ready for commands</strong> | 
                ğŸŒ Connected Nodes: Active | 
                ğŸ”’ WCAG 2.1 AA Compliant | 
                ğŸ¤– Professional AI Mode | 
                ğŸ“¡ Real-time Monitoring
                </div>
                """,
                elem_classes="status-bar"
            )
        
        # Event Handlers
        def send_message(msg, hist, sid):
            return nacc.handle_chat(msg, hist, sid)
        
        send_btn.click(
            fn=send_message,
            inputs=[msg_input, chatbot, session_id],
            outputs=[chatbot, msg_input, dashboard_output, file_output, session_id]
        )
        
        msg_input.submit(
            fn=send_message,
            inputs=[msg_input, chatbot, session_id],
            outputs=[chatbot, msg_input, dashboard_output, file_output, session_id]
        )
        
        # File browser navigation - SESSION AWARE
        def go_to_path(path, sid):
            session = nacc.get_or_create_session(sid)
            session.current_path = path
            return nacc.list_files_view(path, session.current_node)
        
        def go_to_parent(path, sid):
            import os
            session = nacc.get_or_create_session(sid)
            parent = os.path.dirname(path) if path != "/" else "/"
            session.current_path = parent
            return parent, nacc.list_files_view(parent, session.current_node)
        
        cd_btn.click(
            fn=go_to_path,
            inputs=[current_path, session_id],
            outputs=[file_output]
        )
        
        up_btn.click(
            fn=go_to_parent,
            inputs=[current_path, session_id],
            outputs=[current_path, file_output]
        )
        
        refresh_btn.click(
            fn=go_to_path,
            inputs=[current_path, session_id],
            outputs=[file_output]
        )
        
        ex1.click(
            fn=lambda h, s: nacc.handle_chat("Show me the real-time network dashboard", h, s),
            inputs=[chatbot, session_id],
            outputs=[chatbot, msg_input, dashboard_output, file_output, session_id]
        )
        
        ex2.click(
            fn=lambda h, s: nacc.handle_chat("List all files on the production server", h, s),
            inputs=[chatbot, session_id],
            outputs=[chatbot, msg_input, dashboard_output, file_output, session_id]
        )
        
        ex3.click(
            fn=lambda h, s: nacc.handle_chat("Execute comprehensive health checks", h, s),
            inputs=[chatbot, session_id],
            outputs=[chatbot, msg_input, dashboard_output, file_output, session_id]
        )
        
        ex4.click(
            fn=lambda h, s: nacc.handle_chat("list available nodes", h, s),
            inputs=[chatbot, session_id],
            outputs=[chatbot, msg_input, dashboard_output, file_output, session_id]
        )
        
        refresh_dash.click(
            fn=nacc.get_dashboard_view,
            outputs=dashboard_output
        )
        
        # Backend management handlers
        def load_backends():
            """Load available backends on startup"""
            choices, info = nacc.get_available_backends()
            status = nacc.get_backend_status()
            # Extract just the values for dropdown
            dropdown_choices = [choice[0] for choice in choices]
            # Default to blaxel-openai if available, else first choice
            default_val = "blaxel-openai"
            # Find the full string that starts with blaxel-openai
            for choice in dropdown_choices:
                if choice.startswith("blaxel-openai"):
                    default_val = choice
                    break
            else:
                default_val = dropdown_choices[0] if dropdown_choices else "modal"
            
            return gr.update(choices=dropdown_choices, value=default_val), info, status
        
        def handle_backend_switch(backend_value, api_key):
            """Handle backend switch button click"""
            # Extract backend name from dropdown label
            backend_name = backend_value.split(" - ")[0] if " - " in backend_value else backend_value
            msg, success = nacc.switch_backend(backend_name, api_key)
            if success:
                status = nacc.get_backend_status()
                return msg, status
            return msg, "âš ï¸ Switch failed"
        
        def handle_refresh_backends():
            """Handle refresh button click"""
            choices, info = nacc.get_available_backends()
            status = nacc.get_backend_status()
            dropdown_choices = [choice[0] for choice in choices]
            return gr.update(choices=dropdown_choices), info, status
        
        # Wire up backend controls
        demo.load(
            fn=load_backends,
            outputs=[backend_dropdown, backend_info, backend_status]
        )
        
        backend_dropdown.change(
            fn=nacc.on_backend_change,
            inputs=[backend_dropdown],
            outputs=[api_key_input]
        )
        
        switch_button.click(
            fn=handle_backend_switch,
            inputs=[backend_dropdown, api_key_input],
            outputs=[backend_info, backend_status]
        )
        
        refresh_backends_btn.click(
            fn=handle_refresh_backends,
            outputs=[backend_dropdown, backend_info, backend_status]
        )
    
    return demo


def main():
    """Main entry point for the professional UI v2"""
    ui = create_professional_ui_v2()
    ui.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False,
        show_error=True,
        favicon_path=None,
        debug=True
    )


if __name__ == "__main__":
    main()
